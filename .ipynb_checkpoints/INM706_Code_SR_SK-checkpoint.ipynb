{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INM706 Deep Learning for Sequence Analysis\n",
    "### Sarah Rhalem (190051884) & Stelios Kliafas (########)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draft Notes/ Working comments:\n",
    "Dataset >> Problem +Evaluation Metric >> Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from torch.utils.data import Dataset, dataloader\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Set to use GPU on device if available:\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sarah\\\\Documents\\\\MSc AI 2020_2021\\\\INM706\\\\INM706_DL_Sequence_Analysis'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dramas                          1384\n",
       "Comedies                        1074\n",
       "Documentaries                    751\n",
       "Action & Adventure               721\n",
       "International TV Shows           690\n",
       "Children & Family Movies         502\n",
       "Crime TV Shows                   369\n",
       "Kids' TV                         359\n",
       "Stand-Up Comedy                  321\n",
       "Horror Movies                    244\n",
       "British TV Shows                 232\n",
       "Docuseries                       194\n",
       "Anime Series                     148\n",
       "International Movies             114\n",
       "TV Comedies                      110\n",
       "Reality TV                       102\n",
       "Classic Movies                    77\n",
       "TV Dramas                         62\n",
       "Movies                            56\n",
       "Thrillers                         49\n",
       "TV Action & Adventure             37\n",
       "Stand-Up Comedy & Talk Shows      33\n",
       "Romantic TV Shows                 28\n",
       "Classic & Cult TV                 21\n",
       "Independent Movies                20\n",
       "Anime Features                    19\n",
       "Music & Musicals                  17\n",
       "Cult Movies                       12\n",
       "TV Shows                          12\n",
       "Sci-Fi & Fantasy                  11\n",
       "TV Horror                         10\n",
       "Romantic Movies                    3\n",
       "Spanish-Language TV Shows          2\n",
       "LGBTQ Movies                       1\n",
       "Sports Movies                      1\n",
       "TV Sci-Fi & Fantasy                1\n",
       "Name: listing, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv dataset, create listing column\n",
    "raw_dataset_df= pd.read_csv(os.path.join(\"Data\\\\netflix_titles.csv\") , encoding=\"utf8\")\n",
    "raw_dataset_df[\"listing\"]= raw_dataset_df[\"listed_in\"].str.split(pat=\",\", n=1).str.get(0)\n",
    "\n",
    "# Cleanse Data\n",
    "raw_dataset_df[\"description\"].isna().sum() # Check null entries for description - None\n",
    "raw_dataset_df[\"plot_description\"]=raw_dataset_df[\"description\"].map(lambda x: re.sub( r'\"', '', x)) # (TO BE UPDATED REMOVES QUOTATION MARKS)\n",
    "\n",
    "raw_dataset_df.listing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a future where the elite inhabit an island paradise far from the crowded slums, you get one chance to join the 3% saved from squalor.'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset_df[\"description\"].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             genre                                   plot_description\n",
      "0  <international>  In a future where the elite inhabit an island ...\n",
      "1          <drama>  After a devastating earthquake hits Mexico Cit...\n",
      "2         <horror>  When an army recruit is found dead, his fellow...\n",
      "3         <action>  In a postapocalyptic world, rag-doll robots hi...\n",
      "4          <drama>  A brilliant group of students become card-coun...\n",
      "['<international>' '<drama>' '<horror>' '<action>' '<crime>'\n",
      " '<documentary>' '<other>' '<comedy>' '<anime>' '<children>' '<romance>']\n"
     ]
    }
   ],
   "source": [
    "# Map each data sample listing to a generic genre\n",
    " \n",
    " # Identify the show listings for mapping to summarised genres\n",
    "raw_dataset_df.listing.value_counts()\n",
    "\n",
    "# map show listing to a specific genre. Note: Listing types with under ~100 data samples are classified under the genre \"Other\"\n",
    "genre_mapping= { \"<romance>\": {\"Romantic TV Shows\", \"Romantic Movies\"} ,\n",
    "                \"<drama>\": {\"Dramas\", \"TV Dramas\"}  ,\n",
    "                 \"<comedy>\": {\"Comedies\", \"Stand-Up Comedy\", \"TV Comedies\", \"Stand-Up Comedy & Talk Shows\"},\n",
    "                 \"<documentary>\": {\"Documentaries\", \"Docuseries\"},\n",
    "                 \"<action>\": {\"Action & Adventure\", \"TV Action & Adventure\"} ,\n",
    "                 \"<international>\": {\"International TV Shows\", \"International Movies\", \"Spanish-Language TV Shows\"},\n",
    "                 \"<children>\": {\"Children & Family Movies\", \"Kids' TV\"},\n",
    "                 \"<crime>\": {\"Crime TV Shows\"},\n",
    "                 \"<horror>\": {\"Horror Movies\", \"TV Horror\"} ,\n",
    "                 \"<anime>\" : {\"Anime Series\", \"Anime Features\"},\n",
    "                 \"<other>\" : {\"Thrillers\", \"British TV Shows\", \"Reality TV\", \"Classic & Cult TV\", \"TV Shows\", \"TV Sci-Fi & Fantasy\",\n",
    "                         \"Classic Movies\", \"Movies\", \"Independent Movies\", \"Cult Movies\", \"Sports Movies\", \"LGBTQ Movies\", \"Music & Musicals\",\n",
    "                         \"Sci-Fi & Fantasy\"} }\n",
    "\n",
    "# function to map listings to genres by dictionary key\n",
    "def map_function(dictionary):\n",
    "    def my_map(x):\n",
    "        res = \"\"\n",
    "        for key in dictionary.keys():\n",
    "            if (x in dictionary[key]):\n",
    "                res = key\n",
    "                break\n",
    "        return res\n",
    "    return my_map\n",
    "\n",
    "# Add genre column based on listing mapping\n",
    "raw_dataset_df[\"genre\"] = raw_dataset_df[\"listing\"].map(map_function(genre_mapping))\n",
    "\n",
    "# Write to txt file\n",
    "plot_dataset_df= raw_dataset_df[[\"genre\",\"plot_description\"]].copy()\n",
    "plot_dataset= plot_dataset_df.to_csv('Data\\\\netflix_plot_dataset.txt', index=False, header=None, sep=\" \")\n",
    "\n",
    "# Sense check - view data header and check all descriptions were mapped\n",
    "print(plot_dataset_df.head())\n",
    "print(plot_dataset_df.genre.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 12 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50269, 768)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Load model and Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model= GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n",
    "model= model.to(device) \n",
    "\n",
    "\n",
    "special_tokens_dict = {\n",
    "                \"bos_token\": \"<|startoftext|>\",\n",
    "                \"eos_token\": \"<|endoftext|>\",\n",
    "               # \"pad_token\": \"<PAD>\", # NOTE: REVIEW CAN BE REMOVED AS PAD TOKEN HAS BEEN SET TO EOS TOKEN\n",
    "                \"additional_special_tokens\": [\n",
    "                    \"<romance>\",\n",
    "                    \"<drama>\",\n",
    "                    \"<comedy>\",\n",
    "                    \"<documentary>\",\n",
    "                    \"<action>\",\n",
    "                    \"<international>\",\n",
    "                    \"<children>\",\n",
    "                    \"<crime>\",\n",
    "                    \"<horror>\",\n",
    "                    \"<anime>\",\n",
    "                    \"<other>\",\n",
    "                ],\n",
    "            }\n",
    "\n",
    "num_of_toks= tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_of_toks, 'tokens')\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class NetflixPlotDataset(Dataset):\n",
    "          def __init__(self, tokenizer=tokenizer, dataset_path=os.path.join(\"Data\\\\netflix_plot_dataset.txt\"), block_size=128): # block_size missing\n",
    "   \n",
    "              with open(dataset_path, encoding=\"utf-8\") as f:\n",
    "                      lines = [\"<|startoftext|>\"+line+\"<|endoftext|>\" for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "              self.examples = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=block_size, truncation=True)[\"input_ids\"] \n",
    "                \n",
    "        \n",
    "          def __len__(self):\n",
    "            return len(self.examples)\n",
    "\n",
    "          def __getitem__(self, i):\n",
    "             return torch.tensor(self.examples[i], dtype=torch.long)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7788"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate dataset and return length\n",
    "dataset=NetflixPlotDataset()\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50257, 50262,     1, 15137,  9397,  2193,   326,   484,   423, 19552,\n",
      "        34843,  1956,    11,   475,  1276,  1907,   284,  1624,   340,   618,\n",
      "          257, 31828, 37591, 15876, 20201,   284,  1011,   340,   625,   526,\n",
      "        50256])\n",
      "<|startoftext|><action>\"Four brothers learn that they have inherited ancestral land, but must fight to claim it when a greedy feudal lord threatens to take it over.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Test 1- Sample 90 from the dataset\n",
    "print(dataset[90])\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(dataset[90])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50257, 50266,     1,  2215,   281,  5428, 10960,   318,  1043,  2636,\n",
      "           11,   465,  5891,  5795,   389,  4137,   284,  7239,   257, 17623,\n",
      "         3200,   326,   338, 36660,   511, 20712,  7022,  3047,  1413,   526,\n",
      "        50256])\n",
      "<|startoftext|><horror>\"When an army recruit is found dead, his fellow soldiers are forced to confront a terrifying secret that's haunting their jungle island training camp.\"<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Test 2- Sample 2 from the dataset\n",
    "print(dataset[2])\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(dataset[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IGNORE BELOW (WORKING NOTES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   40,   716, 48718])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_length=100, num_beans=5, no_repeat_ngram_size=2, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     f =open('Data\\\\netflix_plot_dataset2.txt','x')\n",
    "# except:\n",
    "#     f =open('Data\\\\netflix_plot_dataset2.txt','x')\n",
    "# for idx in range(raw_dataset_df.shape[0]):\n",
    "#     f.write(raw_dataset_df.iloc[idx]['genre']+' '+raw_dataset_df.iloc[idx]['plot_description']+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
